# -*- coding: utf-8 -*-
"""zigzag_crawling.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1K1W22aPhmlmcritqVcDG7PMtLSoRb8aE
"""

# 필요한 라이브러리 임포트
import pandas as pd  # 데이터프레임 작업을 위한 pandas 라이브러리
import time  # 대기 시간을 설정하기 위한 time 모듈
import csv  # CSV 파일을 처리하기 위한 csv 모듈
from selenium import webdriver  # Selenium을 통해 브라우저를 제어하기 위한 모듈
from webdriver_manager.chrome import ChromeDriverManager  # 드라이버 자동 설치를 위한 모듈
from selenium.webdriver.chrome.service import Service  # ChromeDriver 서비스를 초기화하기 위한 모듈
from selenium.webdriver.common.by import By  # 요소를 찾기 위한 검색 조건 정의 모듈
from selenium.webdriver.common.action_chains import ActionChains  # 액션 체인을 사용한 복잡한 동작 구현 모듈
from selenium.webdriver.support import expected_conditions as EC  # 특정 조건 대기 모듈
from selenium.webdriver.support.ui import WebDriverWait  # 명시적 대기를 위한 모듈
from selenium.webdriver.common.keys import Keys  # 키 입력 동작 구현을 위한 모듈

# 페이지를 스크롤하여 리뷰를 로드하는 함수
def scroll_to_load_reviews(driver, start_num, end_num):
    print(f"리뷰 {start_num}부터 {end_num}까지 스크롤 로드 시작...")
    loaded_reviews = set()  # 중복 방지용
    while len(loaded_reviews) < (end_num - start_num + 1):
        driver.find_element(By.TAG_NAME, "body").send_keys(Keys.END)
        time.sleep(1.5)  # 스크롤 후 대기
        reviews = driver.find_elements(By.CSS_SELECTOR, "#__next > div.zds-themes.light-theme > div > div > div.css-xk426o.eebc9th5 > div > div")
        for num, review in enumerate(reviews, start=1):
            if start_num <= num <= end_num:
                loaded_reviews.add(num)
        print(f"스크롤 완료: {len(loaded_reviews)}/{end_num - start_num + 1}", end="\r")
    print(f"\n스크롤 완료. 총 {len(loaded_reviews)} 리뷰 로드!")

# 리뷰 데이터를 수집하는 함수
def crawl_reviews(driver, product_id, start_num, end_num):
    print(f"리뷰 {start_num}부터 {end_num}까지 데이터 수집 시작...")
    reviews_data = []
    for num in range(start_num, end_num + 1):
        try:
            # 데이터 추출
            reviewer_id = driver.find_element(By.CSS_SELECTOR,
                f"div:nth-child({num}) > div.css-vbvoj0.e13bai5o0 > div.css-1ecn1de.e13bai5o0 > div.css-o3enub.e1umgzx81 > div.css-4ku0lv.e13bai5o0 > p").text
            reviewer_grade = driver.find_element(By.CSS_SELECTOR,
                f"div:nth-child({num}) > div.css-vbvoj0.e13bai5o0 > div.css-1ecn1de.e13bai5o0 > div.css-o3enub.e1umgzx81 > div.css-4ku0lv.e13bai5o0 > span").text
            review_date = driver.find_element(By.CSS_SELECTOR,
                f"div:nth-child({num}) > div.css-vbvoj0.e13bai5o0 > div.css-1ecn1de.e13bai5o0 > div.css-u4mbk0.eimmef70 > div.css-1xqlji6.eimmef70 > span.zds4_s96ru86.zds4_s96ru81c").text
            review_content = driver.find_element(By.CSS_SELECTOR,
                f"div:nth-child({num}) > div.css-vbvoj0.e13bai5o0 > div:nth-child(3) > span").text

            option1 = driver.find_element(By.CSS_SELECTOR,
                f"#__next > div.zds-themes.light-theme > div > div > div.css-xk426o.eebc9th5 > div > div:nth-child({num}) > div.css-vbvoj0.e13bai5o0 > div:nth-child(3) > div > div > div:nth-child(1) > p > span:nth-child(1)").text
            option2 = driver.find_element(By.CSS_SELECTOR,
                f"#__next > div.zds-themes.light-theme > div > div > div.css-xk426o.eebc9th5 > div > div:nth-child({num}) > div.css-vbvoj0.e13bai5o0 > div:nth-child(3) > div > div > div:nth-child(1) > p > span:nth-child(2)").text
            size = driver.find_element(By.CSS_SELECTOR,
                f"#__next > div.zds-themes.light-theme > div > div > div.css-xk426o.eebc9th5 > div > div:nth-child({num}) > div.css-vbvoj0.e13bai5o0 > div:nth-child(3) > div > div > div.css-1wzypsy.eimmef70 > div:nth-child(1) > p").text
            quality = driver.find_element(By.CSS_SELECTOR,
                f"#__next > div.zds-themes.light-theme > div > div > div.css-xk426o.eebc9th5 > div > div:nth-child({num}) > div.css-vbvoj0.e13bai5o0 > div:nth-child(3) > div > div > div.css-1wzypsy.eimmef70 > div:nth-child(2) > p").text
            color = driver.find_element(By.CSS_SELECTOR,
                f"#__next > div.zds-themes.light-theme > div > div > div.css-xk426o.eebc9th5 > div > div:nth-child({num}) > div.css-vbvoj0.e13bai5o0 > div:nth-child(3) > div > div > div.css-1wzypsy.eimmef70 > div:nth-child(3) > p").text
            height = driver.find_element(By.CSS_SELECTOR,
                f"#__next > div.zds-themes.light-theme > div > div > div.css-xk426o.eebc9th5 > div > div:nth-child({num}) > div.css-vbvoj0.e13bai5o0 > div:nth-child(3) > div > div > div:nth-child(3) > p > span:nth-child(1)").text
            weight = driver.find_element(By.CSS_SELECTOR,
                f"#__next > div.zds-themes.light-theme > div > div > div.css-xk426o.eebc9th5 > div > div:nth-child({num}) > div.css-vbvoj0.e13bai5o0 > div:nth-child(3) > div > div > div.css-1wzypsy.eimmef70 > div:nth-child(2) > p").text
            customer_size = driver.find_element(By.CSS_SELECTOR,
                f"#__next > div.zds-themes.light-theme > div > div > div.css-xk426o.eebc9th5 > div > div:nth-child({num}) > div.css-vbvoj0.e13bai5o0 > div:nth-child(3) > div > div > div:nth-child(3) > p > span:nth-child(3)").text

            # 데이터 저장
            reviews_data.append({
                "유저 ID": reviewer_id,
                "리뷰어 등급": reviewer_grade,
                "작성 날짜": review_date,
                "리뷰 내용": review_content,
                "옵션1": option1,
                "옵션2": option2,
                "선택 사이즈": size,
                "퀄리티": quality,
                "색감": color,
                "고객 신장": height,
                "고객 중량": weight,
                "고객 사이즈": customer_size
            })
            print(f"리뷰 {num} 수집 완료.", end="\r")
        except Exception as e:
            print(f"\n리뷰 {num} 수집 중 오류 발생: {e}")
            continue
    print(f"\n리뷰 {start_num}부터 {end_num}까지 데이터 수집 완료!")
    return reviews_data

# 수집된 리뷰 데이터를 CSV 파일로 저장하는 함수
def save_to_csv(data, product_id, start_num, end_num):
    filename = f"reviews_{product_id}_{start_num}_to_{end_num}.csv"
    df = pd.DataFrame(data)
    df.to_csv(filename, index=False, encoding="utf-8-sig")
    print(f"리뷰 데이터를 '{filename}'에 저장했습니다.")

# 메인 실행 코드
if __name__ == "__main__":
    product_ids = ["131506009"]  # 수집할 상품 ID 목록
    ranges = [(1, 1000), (1001, 2000)]  # 스크롤 범위 정의

    for product_id in product_ids:
        for start_num, end_num in ranges:
            print(f"\n=== 상품 ID {product_id}, {start_num}~{end_num} 리뷰 수집 시작 ===")
            driver = None
            try:
                # 웹드라이버 초기화 및 페이지 접속
                driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))
                driver.get(f"https://zigzag.kr/review/list/{product_id}")
                time.sleep(3)  # 페이지 로드 대기

                # 스크롤 및 리뷰 데이터 수집
                scroll_to_load_reviews(driver, start_num, end_num)
                reviews = crawl_reviews(driver, product_id, start_num, end_num)
                save_to_csv(reviews, product_id, start_num, end_num)

            except Exception as e:
                print(f"오류 발생: {e}")
            finally:
                if driver:
                    driver.quit()
